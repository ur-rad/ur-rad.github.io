---
title: "A Survey of Robotic Language Grounding: Tradeoffs between Symbols and Embeddings"
abstract: "With large language models, robots can understand language more flexibly and more capable than ever before. This survey reviews and situates recent literature into a spectrum with two poles: 1) mapping between language and some manually defined formal representation of meaning, and 2) mapping between language and high-dimensional vector spaces that translate directly to low-level robot policy. Using a formal representation allows the meaning of the language to be precisely represented, limits the size of the learning problem, and leads to a framework for interpretability and formal safety guarantees. Methods that embed language and perceptual data into high-dimensional spaces avoid this manually specified symbolic structure and thus have the potential to be more general when fed enough data but require more data and computing to train. We discuss the benefits and tradeoffs of each approach and finish by providing directions for future work that achieves the best of both worlds."
authors:
  - name: "Vanya Cohen"
    affiliationIndices: [0]
  - name: "Jason Xinyu Liu"
    affiliationIndices: [1]
  - name: "Raymond Mooney"
    affiliationIndices: [0]
  - name: "Stefanie Tellex"
    affiliationIndices: [1,2]
  - name: "David Watkins"
    affiliationIndices: [2]
affiliations:
  - "UT Austin"
  - "Brown University"
  - "The AI Institute"
tags: ["language-grounding", "symbolic-reasoning", "neural-embeddings", "natural-language-processing", "robotics", "survey", "representation-learning", "human-robot-interaction"]
publishDate: "2024-11-07T16:00:00Z"
draft: false
pdfUrl: "https://drive.google.com/file/d/1lbDF3jKypjlhYFHja9DGIr6Hixg83q_s/view"
---
