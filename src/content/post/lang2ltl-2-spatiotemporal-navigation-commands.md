---
title: "Lang2LTL-2: Grounding Spatiotemporal Navigation Commands Using Large Language and Vision-Language Models"
abstract: "Grounding spatiotemporal navigation commands to structured task specifications enables autonomous robots to understand a broad range of natural language and solve long-horizon tasks with safety guarantees. Prior works mostly focus on grounding spatial or temporally extended language for robots. We propose Lang2LTL-2, a modular system that leverages pretrained large language and vision-language models and multimodal semantic information to ground spatiotemporal navigation commands in novel city-scaled environments without retraining. Lang2LTL-2 achieves 93.53% language grounding accuracy on a dataset of 21,780 semantically diverse natural language commands in unseen environments. We run an ablation study to validate the need for different modalities. We also show that a physical robot equipped with the same system without modification can execute 50 semantically diverse natural language commands in both indoor and outdoor environments."
authors:
  - name: "Jason Xinyu Liu"
    affiliationIndices: [0]
  - name: "Ankit Shah"
    affiliationIndices: [0]
  - name: "George Konidaris"
    affiliationIndices: [0]
  - name: "Stefanie Tellex"
    affiliationIndices: [0]
  - name: "David Paulius"
    affiliationIndices: [0]
affiliations:
  - "Brown University"
tags: ["natural-language-processing", "linear-temporal-logic", "robot-navigation", "language-grounding", "large-language-models", "vision-language-models", "spatiotemporal-reasoning", "formal-methods", "navigation-commands"]
publishDate: "2024-11-08T16:00:00Z"
draft: false
pdfUrl: "https://drive.google.com/file/d/1XCKm9-Sip3zqcpGEtvtaNLrpO0UdMWna/view"
---
